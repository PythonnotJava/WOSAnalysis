PT J
AU Ikuyajolu, OJ
   Van Roekel, L
   Brus, SR
   Thomas, EE
   Deng, Y
   Sreepathi, S
AF Ikuyajolu, Olawale James
   Van Roekel, Luke
   Brus, Steven R.
   Thomas, Erin E.
   Deng, Yi
   Sreepathi, Sarat
TI Porting the WAVEWATCH III (v6.07) wave action source terms to GPU
SO GEOSCIENTIFIC MODEL DEVELOPMENT
LA English
DT Article
ID EARTH SYSTEM MODEL; HINDCAST; IMPACTS
AB Surface gravity waves play a critical role in several processes, including mixing, coastal inundation, and surface fluxes. Despite the growing literature on the importance of ocean surface waves, wind-wave processes have traditionally been excluded from Earth system models (ESMs) due to the high computational costs of running spectral wave models. The development of the Next Generation Ocean Model for the DOE's (Department of Energy) E3SM (Energy Exascale Earth System Model) Project partly focuses on the inclusion of a wave model, WAVEWATCH III (WW3), into E3SM. WW3, which was originally developed for operational wave forecasting, needs to be computationally less expensive before it can be integrated into ESMs. To accomplish this, we take advantage of heterogeneous architectures at DOE leadership computing facilities and the increasing computing power of general-purpose graphics processing units (GPUs). This paper identifies the wave action source terms, W3SRCEMD, as the most computationally intensive module in WW3 and then accelerates them via GPU. Our experiments on two computing platforms, Kodiak (P100 GPU and Intel(R) Xeon(R) central processing unit, CPU, E5-2695 v4) and Summit (V100 GPU and IBM POWER9 CPU) show respective average speedups of 2x and 4x when mapping one Message Passing Interface (MPI) per GPU. An average speedup of 1.4x was achieved using all 42 CPU cores and 6 GPUs on a Summit node (with 7 MPI ranks per GPU). However, the GPU speedup over the 42 CPU cores remains relatively unchanged (similar to 1.3x) even when using 4 MPI ranks per GPU (24 ranks in total) and 3 MPI ranks per GPU (18 ranks in total). This corresponds to a 35 %-40 % decrease in both simulation time and usage of resources. Due to too many local scalars and arrays in the W3SRCEMD subroutine and the huge WW3 memory requirement, GPU performance is currently limited by the data transfer bandwidth between the CPU and the GPU. Ideally, OpenACC routine directives could be used to further improve performance. However, W3SRCEMD would require significant code refactoring to make this possible. We also discuss how the trade-off between the occupancy, register, and latency affects the GPU performance of WW3.
C1 [Ikuyajolu, Olawale James; Deng, Yi] Georgia Inst Technol, Earth & Atmospher Sci, Atlanta, GA 30332 USA.
   [Ikuyajolu, Olawale James; Deng, Yi] Georgia Inst Technol, Program Ocean Sci & Engn, Atlanta, GA 30332 USA.
   [Van Roekel, Luke; Thomas, Erin E.] Alamos Natl Lab, Fluid Dynam & Solid Mech T 3, Los Alamos, NM USA.
   [Brus, Steven R.] Argonne Natl Lab, Math & Comp Sci Div, Lemont, IL USA.
   [Sreepathi, Sarat] Oak Ridge Natl Lab, Computat Sci & Engn Div, Oak Ridge, TN USA.
C3 University System of Georgia; Georgia Institute of Technology;
   University System of Georgia; Georgia Institute of Technology; United
   States Department of Energy (DOE); Los Alamos National Laboratory;
   United States Department of Energy (DOE); Argonne National Laboratory;
   United States Department of Energy (DOE); Oak Ridge National Laboratory
RP Ikuyajolu, OJ (通讯作者)，Georgia Inst Technol, Earth & Atmospher Sci, Atlanta, GA 30332 USA.
EM oikuyajolu3@gatech.edu
RI Brus, Steven/ABB-8389-2021; Ikuyajolu, Olawale/JDM-3324-2023; Deng,
   Yi/K-6664-2012
OI Deng, Yi/0000-0003-0659-2767; Thomas, Erin E./0000-0002-3146-8998;
   Sreepathi, Sarat/0000-0002-4978-9423; Ikuyajolu, Olawale
   James/0009-0002-7707-6452; Brus, Steven/0000-0002-0314-9201; Van Roekel,
   Luke/0000-0003-1418-5686
FU US Department of Energy's Office of Science (ESMD-SFA)
FX This research has been supported by the US Department of Energy's Office
   of Science (ESMD-SFA).
NR 46
TC 3
Z9 3
U1 0
U2 2
PU COPERNICUS GESELLSCHAFT MBH
PI GOTTINGEN
PA BAHNHOFSALLEE 1E, GOTTINGEN, 37081, GERMANY
SN 1991-959X
EI 1991-9603
J9 GEOSCI MODEL DEV
JI Geosci. Model Dev.
PD MAR 3
PY 2023
VL 16
IS 4
BP 1445
EP 1458
DI 10.5194/gmd-16-1445-2023
PG 14
WC Geosciences, Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geology
GA 9N9BA
UT WOS:000943202100001
OA gold
DA 2025-05-29
ER
